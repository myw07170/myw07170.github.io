

<!DOCTYPE html>
<html lang="en" >



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/avatar-3.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#fc9d9a">
  <meta name="author" content="MYW">
  <meta name="keywords" content="">
  
    <meta name="description" content="This research is devoted to discussing the problem of target rotation detection based on 3D point cloud, and uses the depth learning model to accurately predict the rotation direction of common target">
<meta property="og:type" content="article">
<meta property="og:title" content="Object Rotation Detection Based on 3D Point Cloud">
<meta property="og:url" content="http://myw07170.github.io/2024/11/10/Rotation/index.html">
<meta property="og:site_name" content="Yiwen Mei">
<meta property="og:description" content="This research is devoted to discussing the problem of target rotation detection based on 3D point cloud, and uses the depth learning model to accurately predict the rotation direction of common target">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://myw07170.github.io/img/Rotation/technology_roadmap.png">
<meta property="og:image" content="http://myw07170.github.io/img/Rotation/scene_picture.png">
<meta property="og:image" content="http://myw07170.github.io/img/Rotation/data_format.png">
<meta property="og:image" content="http://myw07170.github.io/img/Rotation/data_enhancement.png">
<meta property="og:image" content="http://myw07170.github.io/img/Rotation/reduce_points.png">
<meta property="og:image" content="http://myw07170.github.io/img/Rotation/add_points.png">
<meta property="og:image" content="http://myw07170.github.io/img/Rotation/12-acc.png">
<meta property="og:image" content="http://myw07170.github.io/img/Rotation/12-err.png">
<meta property="og:image" content="http://myw07170.github.io/img/Rotation/18-acc.png">
<meta property="og:image" content="http://myw07170.github.io/img/Rotation/18-err.png">
<meta property="article:published_time" content="2024-11-10T03:29:33.000Z">
<meta property="article:modified_time" content="2024-11-14T10:01:49.389Z">
<meta property="article:author" content="MYW">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://myw07170.github.io/img/Rotation/technology_roadmap.png">
  
  
  
  <title>Object Rotation Detection Based on 3D Point Cloud - Yiwen Mei</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"myw07170.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":30,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Yiwen Mei</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Object Rotation Detection Based on 3D Point Cloud"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-11-10 11:29" pubdate>
          November 10, 2024
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    

    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">Object Rotation Detection Based on 3D Point Cloud</h1>
            
            
              <div class="markdown-body">
                
                <!-- # Object Rotation Detection Based on 3D Point Cloud -->

<blockquote>
<p><em><strong>Undergraduate Thesis</strong><br>Advisor: Prof. Lili Yang<br>Author: Yiwen Mei<br>Oct. 2023-Jun. 2024</em></p>
</blockquote>
<h1 id="1-Brief-Introduction"><a href="#1-Brief-Introduction" class="headerlink" title="1. Brief Introduction"></a>1. Brief Introduction</h1><ul>
<li><p>Research objective: Through in-depth analysis and processing of 3D point cloud data, develop a tool that can automatically label the object orientation in the data, that is, predict the orientation Angle of the target object and label it.</p>
</li>
<li><p>The technical route of this research is shown in the figure below, and the research background, research purpose and research significance are clearly defined in the project selection stage. Then I looked up and learned relevant literature. Through careful study of literature, I learned the theoretical basis and model framework of relevant algorithms, and tried to reproduce the model. At the same time, self-built data sets were created and processed. Relevant data were first collected, manually marked, then data enhancement and scale unification were carried out, and then data set formats were adjusted, categories were divided, and training sets and test sets were divided according to experimental needs. Finally, the selected model framework is trained with the created data set, and the relevant data of the final training results are obtained after repeated inspection and adjustment.</p>
</li>
</ul>
<p  align = "center">
<img  src="/img/Rotation/technology_roadmap.png" srcset="/img/loading.gif" lazyload  width="450"  />
</p>
<center>technology roadmap</center>

<h1 id="2-Construction-of-Data-Sets"><a href="#2-Construction-of-Data-Sets" class="headerlink" title="2. Construction of Data Sets"></a>2. Construction of Data Sets</h1><h3 id="2-1-Data-set-acquisition-and-annotation"><a href="#2-1-Data-set-acquisition-and-annotation" class="headerlink" title="2.1 Data set acquisition and annotation"></a>2.1 Data set acquisition and annotation</h3><p> <em><strong>1. data collection</strong></em></p>
<ul>
<li><strong>Lidar</strong> technology was used to select diverse road scenes in different time periods on the campus of China Agricultural University, and data were collected for three different common road objects – <strong>pedestrians, cars and cyclists</strong>. The collected data were systematically classified and saved in the folder “imageFile” and “pointCloudFile” respectively. The imageFile folder stores diversified scene images in.jpg format, including <strong>daytime, evening, and night</strong> road scene images. The “pointCloudFile” folder stores the 3D point cloud data of each target object in the form of a.txt text file. Each text file contains three fields, which are the x,y and z coordinates of each point in its point cloud, and these coordinate information accurately describe the position and shape of the target object in space.</li>
</ul>
<p  align = "center">
<img  src="/img/Rotation/scene_picture.png" srcset="/img/loading.gif" lazyload  width="600"  />
</p>
<center>Scene pictures</center>


<ul>
<li>Through the above data collection and storage process, a high-quality original data set is constructed in this paper. The dataset contains a total of 1,043 images covering a diverse range of road environments and lighting conditions, as well as 3D point cloud data for a total of <strong>1,986 objects</strong>, which fall into three categories: pedestrians, cars and cyclists. The establishment of this data set provides a solid foundation for the subsequent data analysis and model training.</li>
</ul>
<style>
.center 
{
  width: auto;
  display: table;
  margin-left: auto;
  margin-right: auto;
}
</style>

<div class="center">

<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">daytime</th>
<th align="center">evening</th>
<th align="center">night</th>
<th align="center">totality</th>
</tr>
</thead>
<tbody><tr>
<td align="center">pedestrians</td>
<td align="center">290</td>
<td align="center">299</td>
<td align="center">621</td>
<td align="center">1210</td>
</tr>
<tr>
<td align="center">cars</td>
<td align="center">125</td>
<td align="center">56</td>
<td align="center">169</td>
<td align="center">350</td>
</tr>
<tr>
<td align="center">cyclists</td>
<td align="center">98</td>
<td align="center">121</td>
<td align="center">207</td>
<td align="center">426</td>
</tr>
<tr>
<td align="center">totality</td>
<td align="center">513</td>
<td align="center">476</td>
<td align="center">997</td>
<td align="center">1986</td>
</tr>
</tbody></table>
</div>


 <!-- ***2. data format***
* The 3D point cloud data of the collected 1986 objects are saved in ''.txt'' format.
* Each file contains three fields representing the x,y, and z coordinates of each point in its point cloud. -->
<!-- <p  align = "center">
<img  src="/img/Rotation/data_format.png" srcset="/img/loading.gif" lazyload  width="400"  />
</p>
<center>data format</center> -->

<p> <em><strong>2. data annotation</strong></em></p>
<ul>
<li>According to the shot picture and visualization point cloud of each target, arbitrarily adjust the Angle of view to judge its orientation.</li>
<li>After adjusting to the <strong>overlooking Angle</strong>, mark the Angle. After marking, add <strong>the fourth field</strong> – Angle label in the target point cloud data file.</li>
<li>The 3D point cloud data of <strong>1191 sample objects</strong> marked with orientation Angle is obtained by removing the data that cannot be judged by human beings.</li>
</ul>
<div class="center">

<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">daytime</th>
<th align="center">evening</th>
<th align="center">night</th>
<th align="center">totality</th>
</tr>
</thead>
<tbody><tr>
<td align="center">pedestrians</td>
<td align="center">176</td>
<td align="center">54</td>
<td align="center">292</td>
<td align="center">522</td>
</tr>
<tr>
<td align="center">cars</td>
<td align="center">123</td>
<td align="center">54</td>
<td align="center">160</td>
<td align="center">337</td>
</tr>
<tr>
<td align="center">cyclists</td>
<td align="center">84</td>
<td align="center">109</td>
<td align="center">139</td>
<td align="center">332</td>
</tr>
<tr>
<td align="center">totality</td>
<td align="center">383</td>
<td align="center">217</td>
<td align="center">591</td>
<td align="center">1191</td>
</tr>
</tbody></table>
</div>

<h3 id="2-2-Data-enhancement"><a href="#2-2-Data-enhancement" class="headerlink" title="2.2 Data enhancement"></a>2.2 Data enhancement</h3><p>Using the <strong>rotation matrix</strong> to achieve data enhancement, a dataset containing <strong>3600</strong> samples is obtained, and there are 10 samples for each Angle orientation.</p>
<p  align = "center">
<img  src="/img/Rotation/data_enhancement.png" srcset="/img/loading.gif" lazyload  width="600"  />
</p>
<center>data enhancement procedure</center>

<h1 id="3-3D-point-cloud-object-rotation-detection-based-on-Pointnet"><a href="#3-3D-point-cloud-object-rotation-detection-based-on-Pointnet" class="headerlink" title="3. 3D point cloud object rotation detection based on Pointnet ++"></a>3. 3D point cloud object rotation detection based on Pointnet ++</h1><h3 id="3-1-Data-preprocessing-The-point-cloud-number-of-each-sample-in-the-data-set-is-unified-to-300"><a href="#3-1-Data-preprocessing-The-point-cloud-number-of-each-sample-in-the-data-set-is-unified-to-300" class="headerlink" title="3.1 Data preprocessing: The point cloud number of each sample in the data set is unified to 300."></a>3.1 Data preprocessing: The point cloud number of each sample in the data set is unified to 300.</h3><h5 id="Reduce-points-FPS-algorithm-combined-with-K-Means-clustering"><a href="#Reduce-points-FPS-algorithm-combined-with-K-Means-clustering" class="headerlink" title="Reduce points: FPS algorithm combined with K-Means clustering"></a>Reduce points: FPS algorithm combined with K-Means clustering</h5><p>Farthest Point Sampling (FPS) algorithm is a common and effective method to reduce the number of point cloud data points. The algorithm constructs a representative point set by iteratively selecting the point farthest from the current point set, thereby simplifying and homogenizing the distribution of data points. In order to further optimize the effect of FPS algorithm, this study introduces K-Means clustering method to improve the selection process of initial points. Specifically, firstly, the K-means algorithm is used to cluster the point cloud data and generate K initial centroid points. FPS sampling is then performed based on these centroid points, thus ensuring that the number of points is effectively reduced while the object’s contour features are preserved. This FPS algorithm combined with K-Means clustering can significantly improve the rationality and efficiency of data point selection.</p>
<p  align = "center">
<img  src="/img/Rotation/reduce_points.png" srcset="/img/loading.gif" lazyload  width="450"  />
</p>
<center>e.g. reduce points</center>


<h4 id="Add-points-Linear-interpolation-algorithm"><a href="#Add-points-Linear-interpolation-algorithm" class="headerlink" title="Add points: Linear interpolation algorithm"></a>Add points: Linear interpolation algorithm</h4><p>The purpose of adding points is to improve the accuracy of the model and the ability to capture detail. This process can be accomplished by simply copying existing data points, but a more precise and efficient way can be achieved by using linear interpolation techniques. Linear interpolation is a mature mathematical method that estimates the value of unknown points by constructing straight lines or curves between known data points, thus effectively filling in the blank areas of the data, thereby enhancing the detail representation and overall accuracy of the model.</p>
<p  align = "center">
<img  src="/img/Rotation/add_points.png" srcset="/img/loading.gif" lazyload  height="250"  />
</p>
<center>e.g. add points</center>

<h3 id="3-2-Model-training-results"><a href="#3-2-Model-training-results" class="headerlink" title="3.2 Model training results"></a>3.2 Model training results</h3><h4 id="Training-process-and-results-of-data-set-1-12-classification"><a href="#Training-process-and-results-of-data-set-1-12-classification" class="headerlink" title="Training process and results of data set 1 (12 classification)"></a>Training process and results of data set 1 (12 classification)</h4><!-- <p  align = "center">
<img  src="/img/Rotation/12-acc.png" srcset="/img/loading.gif" lazyload  height="250"  />
</p>
<center></center>

<p  align = "center">
<img  src="/img/Rotation/12-err.png" srcset="/img/loading.gif" lazyload  height="250"  />
</p>
<center></center> -->
<ul>
<li>After 300 training iterations, the PointNet++ model achieved significant performance improvements on the self-built dataset 1 above. In order to select the optimal model, this paper evaluates the model based on the accuracy of the test set, and saves the results of the round with the highest accuracy of the test set. The final performance is summarized in the following table, where the training set reaches an accuracy of about 95.03%, indicating that the model effectively learns the features of the data set. The accuracy of the test set is about 84.03%, which reflects the generalization ability of the model on new data.</li>
<li>In order to evaluate the performance of the model more comprehensively, the average Angle error is further calculated. As can be seen from the table, the average Angle error of the training set is 10.38°, which shows the high precision of the model in classification Angle. The average Angle error of the test set is 14.84°, which is slightly higher than that of the training set, but still within the acceptable range, indicating that the model can still maintain good performance in the face of unseen data. These results provide a valuable reference for the follow-up research.</li>
</ul>
<style>
.center 
{
  width: auto;
  display: table;
  margin-left: auto;
  margin-right: auto;
}
</style>

<div class="center">

<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">Accuracy</th>
<th align="center">Average Angle Error</th>
</tr>
</thead>
<tbody><tr>
<td align="center">training set</td>
<td align="center">95.03%</td>
<td align="center">10.38°</td>
</tr>
<tr>
<td align="center">test set</td>
<td align="center">84.03%</td>
<td align="center">14.84°</td>
</tr>
</tbody></table>
</div>

<h4 id="Training-process-and-results-of-data-set-2-18-classification"><a href="#Training-process-and-results-of-data-set-2-18-classification" class="headerlink" title="Training process and results of data set 2 (18 classification)"></a>Training process and results of data set 2 (18 classification)</h4><!-- <p  align = "center">
<img  src="/img/Rotation/18-acc.png" srcset="/img/loading.gif" lazyload  height="500"  />
</p>
<center></center>

<p  align = "center">
<img  src="/img/Rotation/18-err.png" srcset="/img/loading.gif" lazyload  height="250"  />
</p>
<center></center> -->

<ul>
<li>After 300 training iterations on the self-built dataset 2, the PointNet++ model also showed significant performance improvements. In order to select the optimal model configuration, this paper evaluates the accuracy of the test set carefully, and saves the results of the round with the highest accuracy of the test set. The final model performance is summarized in the following table: On the training set, the PointNet++ model achieves about 90.90% accuracy, which fully proves that the model can effectively learn and capture key features in dataset 2. On the test set, the model also achieved an accuracy of about 75.69%, which indicates that the model shows strong generalization ability in the face of new data.</li>
<li>Furthermore, the average Angle error of the training set and the test set is calculated. The average Angle error of the training set is 8.21°, which indicates that the model has a high accuracy in the classification Angle. Although the average Angle error of the test set is 12.53°, which is slightly higher than that of the training set, this value is still within the acceptable range, which once again verifies the good performance of the model on the unseen data. These detailed performance evaluation results not only provide a strong support for the current research, but also provide a valuable reference for the subsequent research work.</li>
</ul>
<div class="center">

<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">Accuracy</th>
<th align="center">Average Angle Error</th>
</tr>
</thead>
<tbody><tr>
<td align="center">training set</td>
<td align="center">90.90%</td>
<td align="center">8.21°</td>
</tr>
<tr>
<td align="center">test set</td>
<td align="center">75.69%</td>
<td align="center">12.53°</td>
</tr>
</tbody></table>
</div>

<p>In summary, compared with dataset 1, the model of dataset 2, although slightly less accurate, showed better performance in terms of average angular error. This result has its inherent logical rationality. Given that the classification accuracy of dataset 2 is set at 20°, compared with the classification accuracy of dataset 1 at 30°, the standard is more refined and the requirements are more stringent, which undoubtedly increases the difficulty of the classification task and leads to a slight decline in the classification accuracy. However, on the other hand, just because data set 2 has higher requirements for classification accuracy, the average Angle error displayed by its model in the prediction process is significantly reduced, which means that the deviation between the predicted value and the real value is effectively controlled. Therefore, for these two training results, we can not simply classify them as good or bad, but should choose and apply the most appropriate model based on the needs of practical applications.</p>
<h3 id="3-3-Effect-display"><a href="#3-3-Effect-display" class="headerlink" title="3.3 Effect display"></a>3.3 Effect display</h3><h1 id="4-Summary-and-prospect"><a href="#4-Summary-and-prospect" class="headerlink" title="4. Summary and prospect"></a>4. Summary and prospect</h1><h3 id="4-1-Summary"><a href="#4-1-Summary" class="headerlink" title="4.1 Summary"></a>4.1 Summary</h3><p>Through rigorous experimental verification, this study not only validates the effectiveness of Pointnet ++ model in 3D point cloud rotation detection tasks, but also provides technical tools for environment perception and decision making of autonomous driving systems. Specifically, the main academic achievements of this research are as follows:</p>
<ol>
<li>A 3D point cloud dataset covering three common objects of pedestrians, cars and cyclists in the road scene was successfully constructed, and the dataset included samples of various rotation angles. Through data enhancement technology, the diversity and distribution balance of data sets are effectively improved, and rich training samples are provided for training models with stronger robustness.</li>
<li>PointNet++ model was used for training, which was systematically trained and tested on self-built data sets. The experimental results show that the model has good performance in classification accuracy and Angle prediction ability. During the training process, the model showed efficient recognition of each rotation Angle, which further verified the great potential of deep learning in processing 3D point cloud data.</li>
<li>Active exploration and attempts are made in the rotation Angle prediction of point cloud data. By combining the existing deep learning model with the self-developed data processing method, remarkable results have been achieved in improving the adaptability and accuracy of the model in complex environments, providing an effective tool for the environment perception and decision making of the autonomous driving system.</li>
</ol>
<h3 id="4-2-Prospect"><a href="#4-2-Prospect" class="headerlink" title="4.2 Prospect"></a>4.2 Prospect</h3><ol>
<li>Model optimization: Further explore the direction of model optimization, try to improve the overall performance and reduce the amount of computation</li>
<li>Accuracy improvement: regression model is introduced to achieve specific numerical prediction of orientation Angle</li>
<li>Field evaluation: The research results are applied to evaluate the model performance in actual vehicle testing</li>
<li>……</li>
</ol>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Object Rotation Detection Based on 3D Point Cloud</div>
      <div>http://myw07170.github.io/2024/11/10/Rotation/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>MYW</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>November 10, 2024</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/11/09/Features/" title="Classification of Lettuce Nitrogen Levels">
                        <span class="hidden-mobile">Classification of Lettuce Nitrogen Levels</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
