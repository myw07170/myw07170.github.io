

<!DOCTYPE html>
<html lang="en" >



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/avatar.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#fc9d9a">
  <meta name="author" content="MYW">
  <meta name="keywords" content="">
  
    <meta name="description" content="Classification of Lettuce Nitrogen Levels Based on the Integration of Hyperspectral and Image Features (National College Student Innovation and Entrepreneurship Project)">
<meta property="og:type" content="article">
<meta property="og:title" content="Classification of Lettuce Nitrogen Levels">
<meta property="og:url" content="http://myw07170.github.io/2024/11/09/Features/index.html">
<meta property="og:site_name" content="Yiwen Mei">
<meta property="og:description" content="Classification of Lettuce Nitrogen Levels Based on the Integration of Hyperspectral and Image Features (National College Student Innovation and Entrepreneurship Project)">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://myw07170.github.io/img/National/Plant-factory.png">
<meta property="og:image" content="http://myw07170.github.io/img/National/Crop_culture_process.png">
<meta property="og:image" content="http://myw07170.github.io/img/National/Hyperspectral_imaging_system.png">
<meta property="og:image" content="http://myw07170.github.io/img/National/Hyperspectral_imaging_system.png">
<meta property="og:image" content="http://myw07170.github.io/img/National/RGB-data.png">
<meta property="og:image" content="http://myw07170.github.io/img/National/nitrogen_content.png">
<meta property="og:image" content="http://myw07170.github.io/img/National/nitrogen_content.png">
<meta property="og:image" content="http://myw07170.github.io/img/National/Comparison.png">
<meta property="og:image" content="http://myw07170.github.io/img/National/Hyperspectral.png">
<meta property="og:image" content="http://myw07170.github.io/img/National/different_bands.png">
<meta property="og:image" content="http://myw07170.github.io/img/National/PCA.png">
<meta property="og:image" content="http://myw07170.github.io/img/National/support_vector.png">
<meta property="og:image" content="http://myw07170.github.io/img/National/PC1_band.png">
<meta property="og:image" content="http://myw07170.github.io/img/National/feature_fusion_model.png">
<meta property="og:image" content="http://myw07170.github.io/img/National/Accuracy.png">
<meta property="og:image" content="http://myw07170.github.io/img/National/Loss.png">
<meta property="article:published_time" content="2024-11-09T04:38:07.000Z">
<meta property="article:modified_time" content="2024-11-16T00:15:56.963Z">
<meta property="article:author" content="MYW">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://myw07170.github.io/img/National/Plant-factory.png">
  
  
  
  <title>Classification of Lettuce Nitrogen Levels - Yiwen Mei</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"myw07170.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":30,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Yiwen Mei</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Classification of Lettuce Nitrogen Levels"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-11-09 12:38" pubdate>
          November 9, 2024
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    

    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">Classification of Lettuce Nitrogen Levels</h1>
            
            
              <div class="markdown-body">
                
                <!-- # Classification of Lettuce Nitrogen Levels Based on the Integration of Hyperspectral and Image Features -->



<blockquote>
<p><em><strong>National College Student Innovation and Entrepreneurship Project</strong></em><br><em>Advisor: Prof. Minjuan Wang</em><br><em>Team member: Xiaohan Wan, <strong>Yiwen Mei</strong>, Zijun Gao</em><br><em>May 2023-Apr. 2024</em></p>
</blockquote>
<h1 id="1-Project-contents"><a href="#1-Project-contents" class="headerlink" title="1. Project contents"></a>1. Project contents</h1><ul>
<li><p>The suitable nitrogen level has an important effect on the production quality of leaf vegetables. The accuracy of single image analysis of leaf dishes is not high, so it is necessary to study the nitrogen stress level of leaf dishes by various methods. In this project, the plant images under different nitrogen stress were collected, and the classification method of nitrogen stress degree of leaf vegetables was improved through the combination of hyperspectral and image characteristics.</p>
</li>
<li><p>The purpose of this project is to explore a rapid and accurate estimation method of nitrogen stress degree of rosella leaves, enrich the theoretical basis of rosella cultivation in plant factories, and have a good practical application prospect for intelligent regulation of nutrient solution composition, monitoring growth, predicting yield and quality in plant factories.</p>
</li>
</ul>
<!-- ![植物工厂图片](/img/National/Plant-factory.png "Plant factory") -->
<p align = "center">    
<img  src="/img/National/Plant-factory.png" srcset="/img/loading.gif" lazyload width="450" />
</p>
<center>Plant factory</center>



<h1 id="2-Completions"><a href="#2-Completions" class="headerlink" title="2. Completions"></a>2. Completions</h1><h2 id="2-1-Plant-experiment-and-data-acquisition"><a href="#2-1-Plant-experiment-and-data-acquisition" class="headerlink" title="2.1 Plant experiment and data acquisition"></a>2.1 Plant experiment and data acquisition</h2><ul>
<li>The four seasons balsamic wheat from Jingnong Research was used as the material in this experiment, which is widely cultivated in the whole country. At present, two batches of rosella planting experiments have been completed in the Plant Factory of the School of Information and Electrical Engineering from June 2023 to August 2023 and from September 2023 to November 2023. The temperature, humidity, CO2 concentration etc. in the plant are adjusted to the best. 1&#x2F;2 Hoagland nutrient solution was used as the substrate. A total of 60 plants were planted in the hydroponic box. In order to collect data of rosella and nitrogen stress, we induced low nitrogen stress and high nitrogen stress by controlling nitrogen concentration in culture medium. The hydroponic box is hung above the plant special light, and the light intensity is controlled by adjusting the knob.</li>
<li>According to the previous investigation results, nitrogen concentration was divided into three levels: <strong>2.5g&#x2F;L</strong> (weak nitrogen stress), <strong>10.5g&#x2F;L</strong> (suitable nitrogen environment), <strong>18.5g&#x2F;L</strong> (strong nitrogen stress).</li>
</ul>
<!-- ![作物培养过程](/img/National/Crop_culture_process.png  "Crop culture process") -->
<p align = "center">    
<img  src="/img/National/Crop_culture_process.png" srcset="/img/loading.gif" lazyload width="600" />
</p>
<center>Crop culture process</center>
  



<!-- * During the three growth stages of the plants, the plants were collected and brought back to the laboratory for scanning using the GaiaSorter indoor hyperspectral imaging system of Beijing Zhuolihan Optical Instrument Co., LTD., to obtain the hyperspectral data of the leaves. 
* The imaging system is equipped with a V10E spectrometer, an OL23 lens, an LT365 detector, two bromo-tungsten light sources and an electronically controlled payload moving platform. The collected spectral range is 382-1026nm, spectral resolution is 2.8nm, sampling interval is 0.65nm, a total of 728 bands. The exposure time of the imaging system is 15ms, and the moving speed of the platform is 0.5mm/s. -->

<!-- ![高光谱影像系统](/img/National/Hyperspectral_imaging_system.png  "Hyperspectral imaging system") -->
<!-- <p align = "center">    
<img  src="/img/National/Hyperspectral_imaging_system.png" srcset="/img/loading.gif" lazyload height="300" />
</p>
<center>Hyperspectral imaging system</center> -->

<p style="width:700px;" >
    <img src="/img/National/Hyperspectral_imaging_system.png" srcset="/img/loading.gif" lazyload style="border: none; box-shadow: none;" align="right" height = "300" hspace="20" vspace="20" >
    <p>During the three growth stages of the plants, the plants were collected and brought back to the laboratory for scanning using the GaiaSorter indoor hyperspectral imaging system of Beijing Zhuolihan Optical Instrument Co., LTD., to obtain the hyperspectral data of the leaves. </p>
    <p>The imaging system is equipped with a V10E spectrometer, an OL23 lens, an LT365 detector, two bromo-tungsten light sources and an electronically controlled payload moving platform. The collected spectral range is 382-1026nm, spectral resolution is 2.8nm, sampling interval is 0.65nm, a total of 728 bands. The exposure time of the imaging system is 15ms, and the moving speed of the platform is 0.5mm/s.</p>
</p>




<ul>
<li>Finally, we obtained the original hyperspectral data of <strong>440 blades</strong>, and converted the hyperspectral data into <strong>RGB image data</strong> through python programming. The following figure shows a sample of our RGB data:</li>
</ul>
<p align = "center">    
<img  src="/img/National/RGB-data.png" srcset="/img/loading.gif" lazyload height="300" />
</p>
<center>RGB image data</center>


<!-- * The leaves of the destructively sampled plants were dried and polished into powder, which was stored in a self-sealing bag for the determination of nitrogen content in the plants. The **nitrogen determination experiment** was carried out in the laboratory of College of Plant Protection, West Campus of China Agricultural University by distillation method. After five steps of deboiling, constant volume, alkalization, distillation and titration, the nitrogen content was obtained by calculating the acid standard liquid consumed during titration.  -->
<!-- The calculation formula is as follows: -->

<!-- ![实验测定氮含量](/img/National/nitrogen_content.png  "The nitrogen content was determined by experiment") -->
<!-- <p align = "center">    
<img  src="/img/National/nitrogen_content.png" srcset="/img/loading.gif" lazyload height="350" />
</p>
<center>The nitrogen content was determined by experiment</center> -->


<p style="width:700px;" >
    <img src="/img/National/nitrogen_content.png" srcset="/img/loading.gif" lazyload style="border: none; box-shadow: none;" align="right" height = "200" hspace="10" vspace="10" >
    <p>The leaves of the destructively sampled plants were dried and polished into powder, which was stored in a self-sealing bag for the determination of nitrogen content in the plants. The nitrogen determination experiment was carried out in the laboratory of College of Plant Protection, West Campus of China Agricultural University by distillation method. After five steps of deboiling, constant volume, alkalization, distillation and titration, the nitrogen content was obtained by calculating the acid standard liquid consumed during titration.  </p>
</p>




<h2 id="2-2-RGB-image-processing-and-feature-extraction"><a href="#2-2-RGB-image-processing-and-feature-extraction" class="headerlink" title="2.2 RGB image processing and feature extraction"></a>2.2 RGB image processing and feature extraction</h2><h4 id="2-2-1-Image-preprocessing"><a href="#2-2-1-Image-preprocessing" class="headerlink" title="2.2.1 Image preprocessing"></a>2.2.1 Image preprocessing</h4><!-- ![U-Net网络结构](/img/National/U-Net.png  "U-Net structure") -->
<p>Since the brightness of the RGB image after hyperspectral conversion is very low, and there are some whiteboard edges, in order to avoid noise pollution of the scanned image as much as possible, we preprocess all the RGB image data, mainly including: brightness enhancement, contrast enhancement, background segmentation and image cropping. In the process of image processing, the image segmentation algorithm based on U-Net was used to segment the main body of rapeseed leaves, and Abode Photoshop CC was used to separate each leaf separately, and the image background was uniformly adjusted to black to eliminate the influence of noise in the image background. The size of the adjusted image is 500 × 500px.</p>
<!-- ![处理前后对比](/img/National/Comparison.png  "Comparison of image samples before and after processing") -->
<p align = "center">    
<img  src="/img/National/Comparison.png" srcset="/img/loading.gif" lazyload height="320" />
</p>
<center>Comparison of image samples before and after processing</center>

<h4 id="2-2-2-Qualitative-estimation-of-nitrogen-content-based-on-RGB-images"><a href="#2-2-2-Qualitative-estimation-of-nitrogen-content-based-on-RGB-images" class="headerlink" title="2.2.2 Qualitative estimation of nitrogen content based on RGB images"></a>2.2.2 Qualitative estimation of nitrogen content based on RGB images</h4><ul>
<li>The RGB images obtained after two crop planting experiments in this project were preprocessed, and more than 400 images were finally obtained. 10% images were used as the test set and the rest as the training set, which constituted the qualitative estimation data set of nitrogen content.</li>
<li>In the establishment of image classification model, this project considers VGGNet, ResNet, GoogleNet, AlexNet and other models, from which the optimal model is selected and improved. As can be seen from the table, VGG16 has a high accuracy rate, but there are still shortcomings.</li>
</ul>
<style>
.center 
{
  width: auto;
  display: table;
  margin-left: auto;
  margin-right: auto;
}
</style>

<div class="center">

<table>
<thead>
<tr>
<th align="center">Model</th>
<th align="center">Average accuracy</th>
</tr>
</thead>
<tbody><tr>
<td align="center">VGG16</td>
<td align="center">52%</td>
</tr>
<tr>
<td align="center">GoogleNet</td>
<td align="center">42%</td>
</tr>
<tr>
<td align="center">AlexNet</td>
<td align="center">34%</td>
</tr>
<tr>
<td align="center">ResNet34</td>
<td align="center">32%</td>
</tr>
</tbody></table>
</div>

<h4 id="2-2-3-Image-feature-extraction"><a href="#2-2-3-Image-feature-extraction" class="headerlink" title="2.2.3 Image feature extraction"></a>2.2.3 Image feature extraction</h4><ul>
<li>The scanned image of rapeseed leaves obtained by the experiment contains rich color and texture information. The above features extracted by image processing technology will become the main basis for the study of digital nitrogen nutrition estimation and modeling.</li>
<li>In this project, standardized RGB values are used to express color features to eliminate the influence of brightness information. At the same time, the RGB color model is converted to the HSI color model by geometric derivation to obtain the hue, saturation and brightness of the image.</li>
<li>In this project, a statistical texture feature, gray co-occurrence matrix (GLCM), was selected. GLCM is a method based on estimating the second-order combined conditional probability density of an image. Six texture features, including angular second moment (ASM), contrast (ContrastCon), Energy (Ene), Homogeneity (Hom), DissimilarityDis (DissimilarityDis) and Correlation (Cor), were extracted.</li>
</ul>
<h2 id="2-3-Hyperspectral-data-processing-and-feature-extraction"><a href="#2-3-Hyperspectral-data-processing-and-feature-extraction" class="headerlink" title="2.3 Hyperspectral data processing and feature extraction"></a>2.3 Hyperspectral data processing and feature extraction</h2><p>Hyperspectral images are rich in information. In this project, we first adopted principal component analysis (PCA) and feature wavelength extraction to preprocess hyperspectral data.</p>
<!-- ![高光谱数据处理](/img/National/Hyperspectral.png  "Hyperspectral data processing") -->
<p align = "center">    
<img  src="/img/National/Hyperspectral.png" srcset="/img/loading.gif" lazyload width="650" />
</p>
<center>Hyperspectral data processing</center>


<h4 id="2-3-1-PCA-principal-component-analysis"><a href="#2-3-1-PCA-principal-component-analysis" class="headerlink" title="2.3.1 PCA(principal component analysis)"></a>2.3.1 PCA(principal component analysis)</h4><ul>
<li><p>Principal component analysis is an effective dimensionality reduction algorithm, which has been widely used in the field of spectral analysis. Principal component analysis is an attempt to explain as much information about the original variable as possible by using a new, unrelated set of variables.</p>
</li>
<li><p>The visual analysis of PC1~5 is carried out. As shown in the figure below, the contribution of PC1 and PC2 is relatively large.</p>
<!-- ![不同波段的贡献度](/img/National/different_bands.png  "The contribution of different bands") -->
  <p align = "center">    
  <img  src="/img/National/different_bands.png" srcset="/img/loading.gif" lazyload height="300" />
  </p>
  <center>The contribution of different bands</center>
</li>
<li><p>The connection between PC1 and PC2 is discussed separately. As shown in the figure below, the data points are relatively dense, which confirms the strong correlation between PC1 and PC2. In this project, PC1 and PC2 were selected to analyze the spectral characteristics.</p>
</li>
</ul>
  <p align = "center">    
  <img  src="/img/National/PCA.png" srcset="/img/loading.gif" lazyload height="300" />
  </p>


<h4 id="2-3-2-Quantitative-estimation-of-nitrogen-content-based-on-hyperspectrum"><a href="#2-3-2-Quantitative-estimation-of-nitrogen-content-based-on-hyperspectrum" class="headerlink" title="2.3.2 Quantitative estimation of nitrogen content based on hyperspectrum"></a>2.3.2 Quantitative estimation of nitrogen content based on hyperspectrum</h4><p>In this project, support vector machine regression (SVR) algorithm was used to predict nitrogen in roselle. The advantage of SVR algorithm is that it introduces the concept of kernel function, through which the low-dimensional nonlinear problem is transformed into a high-dimensional space, so that it becomes a linear problem, which can solve the complex problem of multivariate variables.</p>
<!-- ![支持向量机回归](/img/National/support_vector.png  "support vector") -->
<p align = "center">    
<img  src="/img/National/support_vector.png" srcset="/img/loading.gif" lazyload height="300" />
</p>
<center>support vector</center>

<p>As can be seen from the table, the accuracy of the model is significantly improved after PC1 and PC2 are selected as the main components, but there are still shortcomings.</p>
<div class="center">

<table>
<thead>
<tr>
<th align="center">Data Set</th>
<th align="center">Accuracy</th>
<th align="center">Recall</th>
</tr>
</thead>
<tbody><tr>
<td align="center">original</td>
<td align="center">0.31</td>
<td align="center">0.33</td>
</tr>
<tr>
<td align="center">PC1, PC2</td>
<td align="center">0.54</td>
<td align="center">0.53</td>
</tr>
</tbody></table>
</div>

<h4 id="2-3-3-Feature-band-selection"><a href="#2-3-3-Feature-band-selection" class="headerlink" title="2.3.3 Feature band selection"></a>2.3.3 Feature band selection</h4><p>Hyperspectrum has the characteristics of large amount of data and strong redundancy between bands, which will have a certain impact on the later data processing and modeling, so it becomes very important to select some representative characteristic wavelengths. We take the absolute value of the average weight coefficient of each wavelength to obtain the actual contribution degree of each feature. The picture shows a visual image of characteristic band analysis of PC1:</p>
<!-- ![对PC1进行特征波段分析](/img/National/PC1_band.png  "PC1 characteristic band analysis")  -->
<p align = "center">    
<img  src="/img/National/PC1_band.png" srcset="/img/loading.gif" lazyload width="600" />
</p>
<center>PC1 characteristic band analysis</center>

<p>As can be seen from the figure, the spectrum with the largest load, that is, the most contribution in the principal component PC1, is concentrated around 220. The wavelength is about 741~775, located in the red edge region. This result coincides with Sun Jun’s hyperspectral data analysis of lettuce, indicating that the characteristic band is closely related to crop nitrogen nutrition and has high analytical value. Therefore, we extracted the spectral data of all 260 leaf samples in this band as the spectral characteristics of the samples, and then stored the spectral data in matrix format to construct the hyperspectral data set of roeseed leaves at a specific wavelength (741-775).</p>
<h2 id="2-4-Fusion-hierarchical-model-based-on-convolutional-neural-network"><a href="#2-4-Fusion-hierarchical-model-based-on-convolutional-neural-network" class="headerlink" title="2.4 Fusion hierarchical model based on convolutional neural network"></a>2.4 Fusion hierarchical model based on convolutional neural network</h2><ul>
<li><p>Fusion model establishment: A feature fusion model based on convolutional neural network is designed to effectively fuse the features of RGB image and HSI data to improve image classification performance</p>
<!-- ![基于CNN的特征融合模型](/img/National/feature_fusion_model.png  "Feature fusion model based on CNN") -->
<p align = "center">    
<img  src="/img/National/feature_fusion_model.png" srcset="/img/loading.gif" lazyload width="900" />
</p>
<center>Feature fusion model based on CNN</center>
</li>
<li><p>This project designed a feature fusion model based on convolutional neural network to effectively fuse the features of RGB image and HSI (Hyperspectral Imaging) data to improve image classification performance. The model uses CNN as the basic architecture, and carries on the corresponding design in the feature extraction part and the classifier part. </p>
</li>
<li><p>The following figure shows the change curve of accuracy and loss after running 1000 epochs. It can be seen from the figure that the accuracy of this model is finally stable at about 67%, and can reach nearly 80% at the highest time, which is better than the effect of single RGB image classification or hyperspectral modeling.</p>
</li>
</ul>
<!-- ![基于CNN的特征融合模型-acc](/img/National/Accuracy.png  "Accuracy")
![基于CNN的特征融合模型-loss](/img/National/Loss.png  "Loss") -->
<p align = "center">    
<img  src="/img/National/Accuracy.png" srcset="/img/loading.gif" lazyload height="300" />
</p>
<center>Accuracy</center>

<p align = "center">    
<img  src="/img/National/Loss.png" srcset="/img/loading.gif" lazyload height="300" />
</p>
<center>Loss</center>

<h1 id="3-Innovation-Points"><a href="#3-Innovation-Points" class="headerlink" title="3. Innovation Points"></a>3. Innovation Points</h1><p><strong>1. The qualitative estimation of nitrogen content of roselle based on RGB image was realized</strong></p>
<ul>
<li>Establish multiple deep learning methods</li>
<li>To provide qualitative reference for nitrogen content in romaine rapeseed leaves</li>
</ul>
<p><strong>2. The quantitative estimation of nitrogen content in romaine was realized based on hyperspectrum</strong></p>
<ul>
<li>The spectral preprocessing and characteristic wavelength extraction were realized by statistical principle</li>
<li>The actual nitrogen content of plants was obtained by stoichiometry</li>
<li>A quantitative estimation model of nitrogen content in rosella was established with characteristic wavelength</li>
</ul>
<p><strong>3. A fusion estimation model of nitrogen stress in rosellas was established</strong></p>
<ul>
<li>A feature fusion model based on convolutional neural network is designed to fuse the features of RGB image and hyperspectral data effectively to improve the performance of image classification</li>
<li>Using CNN as the infrastructure and designing the feature extraction part and classifier part, the accuracy of nitrogen content estimation model is higher than that of single image or hyperspectral model</li>
</ul>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Classification of Lettuce Nitrogen Levels</div>
      <div>http://myw07170.github.io/2024/11/09/Features/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>MYW</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>November 9, 2024</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/11/10/Rotation/" title="Object Rotation Detection Based on 3D Point Cloud">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Object Rotation Detection Based on 3D Point Cloud</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
